{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4GISnvWUvr4",
        "outputId": "7cfeee31-8280-44bc-9188-cd0dfd6a2820"
      },
      "outputs": [],
      "source": [
        "#load Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#show all columns\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Epsilon/Epsilon Final Project/heart_2022_with_nans.csv')\n",
        "\n",
        "\n",
        "#show all columns\n",
        "#pd.set_option('display.max_columns', None)\n",
        "\n",
        "#df = pd.read_csv('heart_2022_with_nans.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "rB8yRDzAOYqI",
        "outputId": "b56029ca-1660-4f19-9cbc-774ae2432f33"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSaFnXztVchD"
      },
      "source": [
        "# Data Exploring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD6FOdtJVvMu",
        "outputId": "19d85943-93b2-42f0-a647-2c7075175d91"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "KtRNfsWyVztk",
        "outputId": "28dd9d68-9c30-4aa1-8d89-489fa66cd834"
      },
      "outputs": [],
      "source": [
        "round(df.describe(include='number'),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "YgrBGPyrV2Q_",
        "outputId": "2eade838-3748-4326-ee91-f60bfd354c0f"
      },
      "outputs": [],
      "source": [
        "df.describe(include='O')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvRmSVZb9kCF"
      },
      "outputs": [],
      "source": [
        "#drop column weight kilogram because BMI is already present\n",
        "df = df.drop(columns=['WeightInKilograms','State','RaceEthnicityCategory','HadAsthma','HadSkinCancer'],axis=1)\n",
        "df.drop_duplicates(inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0GLIKG2V8Df",
        "outputId": "56dbd1c1-5882-4d5d-ddc7-597e3d4a3f4d"
      },
      "outputs": [],
      "source": [
        "Num_columns = df.select_dtypes(include=['number']).columns\n",
        "Num_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMUHeaP3V-oh"
      },
      "outputs": [],
      "source": [
        "cat_columns = df.select_dtypes(include=['object']).columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH17XS1tWA1s",
        "outputId": "b93b65d1-016f-42e2-e06d-6215b9703359"
      },
      "outputs": [],
      "source": [
        "for col in cat_columns:\n",
        "    print(f\"{col}: {df[col].unique()}\")\n",
        "    print(\"*\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "NN2q9UjQ9kCG",
        "outputId": "108d0e7f-8f94-4853-f8a1-867ad2416188"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmKqi0vsWFAx"
      },
      "source": [
        "## In depth check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsGUTjDUWHhU",
        "outputId": "cfc3336f-e4b9-45d5-8fdd-99c56bed991e"
      },
      "outputs": [],
      "source": [
        "for col in Num_columns:\n",
        "\n",
        "    px.histogram(data_frame= df, x= col).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wi54e9ufEAq"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAFLAA_Ua9lQ"
      },
      "outputs": [],
      "source": [
        "#drop duplicates\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "#get the nan values Percentage for number columns\n",
        "df_num_sorted = df[Num_columns].isna().mean().sort_values(ascending=False) * 100\n",
        "\n",
        "#get the nan values Percentage for categorical columns\n",
        "df_cat_sorted = df[cat_columns].isna().mean().sort_values(ascending=False) * 100\n",
        "\n",
        "#get number columns  have nan <5% and drop the rows\n",
        "cols_to_dropna = df_num_sorted[df_num_sorted < 5].index.tolist()\n",
        "cols_to_dropna+=df_cat_sorted[df_cat_sorted < 5].index.tolist()\n",
        "\n",
        "df.dropna(subset=cols_to_dropna, inplace=True)\n",
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZYJb_IrfPlN",
        "outputId": "3f880ef1-23f1-4f5a-dd81-31211e0d246e"
      },
      "outputs": [],
      "source": [
        "#get the remaining nan values Percentage for number columns\n",
        "df_num_sorted = df[Num_columns].isna().mean().sort_values(ascending=False) * 100\n",
        "nan_col_num =df_num_sorted[df_num_sorted>0].index\n",
        "nan_col_num"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOzvBSSjfRxw",
        "outputId": "fb353f6b-bd73-438d-f998-c458d2b8995a"
      },
      "outputs": [],
      "source": [
        "#get the remaining nan values Percentage for categorical columns\n",
        "df_cat_sorted = df[cat_columns].isna().mean().sort_values(ascending=False) * 100\n",
        "nan_col_cat =df_cat_sorted[df_cat_sorted>0].index\n",
        "nan_col_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-bpvo5dfjO4"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b-rnTb2k1p_T"
      },
      "outputs": [],
      "source": [
        "#replace Never used e-cigarettes in my entire life,Not at all (right now) to =>Not at all\n",
        "df[\"ECigaretteUsage\"]=df[\"ECigaretteUsage\"].replace({\"Never used e-cigarettes in my entire life\":\"Not at all\",\"Not at all (right now)\":\"Not at all\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65NMpKI5_Sua",
        "outputId": "03f9200d-979d-4c20-d27b-3dc8b193b4a6"
      },
      "outputs": [],
      "source": [
        "#check the percentage of data of each category in the categorical columns\n",
        "for col in nan_col_cat:\n",
        "    print(f\"{col}: {df[col].value_counts()/df[col].shape[0]*100}\")\n",
        "    print(\"*\" * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnDyO7UVD7xj",
        "outputId": "90f2f57f-7f1d-4954-bad7-2d2c3aa1fefc"
      },
      "outputs": [],
      "source": [
        "#Check Encoder Type for each column\n",
        "for col in cat_columns:\n",
        "    print(f\"{col}: {df[col].value_counts(normalize=True)*100}\")\n",
        "    print(\"*\" * 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akt9jl8wcsjf"
      },
      "source": [
        "# Pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZEk8h14f_IM"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFLD5CzTdFpq"
      },
      "outputs": [],
      "source": [
        "y= df[\"HadHeartAttack\"].map({'Yes': 1, 'No': 0})\n",
        "x = df.drop(\"HadHeartAttack\", axis=1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42,shuffle=True,stratify=y)\n",
        "cat_columns = x_train.select_dtypes(include=['object']).columns\n",
        "Num_columns = x_train.select_dtypes(include=['number']).columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6YKyGl7mh35"
      },
      "source": [
        "## Class weight calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTdfJ-lsmdMR",
        "outputId": "9cfb3d42-c60e-45f9-a628-d5aea8bfbd3b"
      },
      "outputs": [],
      "source": [
        "df_count = y_train.value_counts()\n",
        "df_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4d828ZVoMNr"
      },
      "outputs": [],
      "source": [
        "negative = df_count[0]\n",
        "positive = df_count[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnzk9s5Umoq1"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A68iSgHjkDHq",
        "outputId": "1472d24c-3313-40c6-da50-6cc37b65c885"
      },
      "outputs": [],
      "source": [
        "#Calculate the XGBoost_scale_pos_weight\n",
        "XGBoost_scale_pos_weight = negative / positive\n",
        "XGBoost_scale_pos_weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxKpSr6smtMW"
      },
      "source": [
        "### CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTHrt3UNmX0o"
      },
      "outputs": [],
      "source": [
        "total =df_count[0] + df_count[1]\n",
        "# compute inverse frequency weights\n",
        "w0 = total / (2 * negative)\n",
        "w1 = total / (2 * positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WEzUBDDjmmG",
        "outputId": "ee23a529-3e94-4830-9cbf-65ba21a4994e"
      },
      "outputs": [],
      "source": [
        "neg, pos = np.bincount(y_train)\n",
        "neg,pos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEZVdtpF61GJ",
        "outputId": "4e4eb1d4-e0a9-48f9-b5a6-579495bf9951"
      },
      "outputs": [],
      "source": [
        "cat_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CClw5hsP64Do",
        "outputId": "d9c9b692-cd92-4786-eaeb-fe45866c1e7e"
      },
      "outputs": [],
      "source": [
        "Num_columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4WdAPQTfr_z"
      },
      "source": [
        "## Categorical pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgchdViz4MMD",
        "outputId": "08397067-97da-4192-c276-85335215523e"
      },
      "outputs": [],
      "source": [
        "#!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-saps0Jf5_i"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
        "from category_encoders import BinaryEncoder\n",
        "\n",
        "FrqImputerOHEncoder_col=[col for col in cat_columns if col not in ['TetanusLast10Tdap','AgeCategory']]#'State',\n",
        "FrqImputerOHEncoder_Pipeline = Pipeline(steps= [('CategoryPipeline_Freq_Imputer', SimpleImputer(strategy='most_frequent')),\n",
        "                                  ('CategoryPipeline_OneHot_Encoder', OneHotEncoder(drop= 'first', sparse_output= False))])\n",
        "\n",
        "ConstImputerOHEncoder_col=[\"TetanusLast10Tdap\"]\n",
        "ConstImputerOHEncoder_Pipeline= Pipeline(steps= [('CategoryPipeline_Constant_Imputer', SimpleImputer(strategy= 'constant', fill_value= 'unKnown')),\n",
        "                                  ('CategoryPipeline_OneHot_Encoder', OneHotEncoder(drop= 'first', sparse_output= False))])\n",
        "\n",
        "#Binary_Encoder_col=['State']\n",
        "#Binary_Encoder_Pipeline = Pipeline(steps=[(\"BinaryEncoder\",BinaryEncoder())])\n",
        "\n",
        "Ordenal_Encoder_col=['AgeCategory']\n",
        "Ordinal_Encoder_Pipeline = Pipeline(steps=[(\"OrdinalEncoder\",OrdinalEncoder(categories= [ ['Age 18 to 24','Age 25 to 29','Age 30 to 34','Age 35 to 39','Age 40 to 44','Age 45 to 49','Age 50 to 54','Age 55 to 59','Age 60 to 64','Age 65 to 69','Age 70 to 74','Age 75 to 79','Age 80 or older'] ]))])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6pQ69_Tc4fh"
      },
      "source": [
        "## numeric pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qt5KGgtodlNs"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "num_pipeline1 = Pipeline(steps= [ ('Simple Impute', SimpleImputer(strategy='median')),\n",
        "                                   ('Robust Scaler', RobustScaler()) ])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU8e_Re25TLt"
      },
      "source": [
        "## Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m-DkhaY5YJN",
        "outputId": "7abc5ef3-0521-4f78-a1b1-fe42adf2f32a"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "preprocessing = ColumnTransformer(transformers= [('num_pipeline1', num_pipeline1, Num_columns),\n",
        "                                  ('FrqImputerOHEncoder_Pipeline', FrqImputerOHEncoder_Pipeline,FrqImputerOHEncoder_col),\n",
        "                                  ('ConstImputerOHEncoder_Pipeline', ConstImputerOHEncoder_Pipeline,ConstImputerOHEncoder_col),\n",
        "                                  #('Binary_Encoder_Pipeline', Binary_Encoder_Pipeline, Binary_Encoder_col),\n",
        "                                  ('Ordinal_Encoder_Pipeline',Ordinal_Encoder_Pipeline,Ordenal_Encoder_col)\n",
        "                                  ]\n",
        "                                  ,remainder= 'passthrough')\n",
        "preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_Fg3m19FZAR"
      },
      "source": [
        "## Models Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knSS6vKqH3um",
        "outputId": "9bd08c24-f6fe-4665-93eb-acb93718c00d"
      },
      "outputs": [],
      "source": [
        "#!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-lejql49kCQ",
        "outputId": "61ce20b1-deed-48a8-e7d3-86c9a90efbd4"
      },
      "outputs": [],
      "source": [
        "#!pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l05GDo4OFeWe"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate, RandomizedSearchCV,GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "models = [\n",
        "    ('Logistic Regression', LogisticRegression(class_weight=\"balanced\",random_state= 42, n_jobs= -1)),\n",
        "   # ('KNN', KNeighborsClassifier(n_jobs= -1)),\n",
        "    ('Gaussian NB', GaussianNB()),\n",
        "    ('Decision Tree', DecisionTreeClassifier(class_weight=\"balanced\",random_state= 42)),\n",
        "    ('Random Forest', RandomForestClassifier(class_weight=\"balanced\",random_state= 42, n_jobs= -1)),\n",
        "    ('XGBoost', XGBClassifier(scale_pos_weight=XGBoost_scale_pos_weight,random_state=42,n_jobs=-1)),\n",
        "    ('CatBoost', CatBoostClassifier(allow_writing_files=False,class_weights=[w0, w1], random_state=42,thread_count=-1)),# order must match class indices (0 = No, 1 = Yes)  ,thread_count =use all available CPU cores\n",
        "    ('LightGBM', LGBMClassifier(class_weight='balanced',random_state=42, n_jobs=-1))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YpgFy2-ph9u",
        "outputId": "c770bdf1-55fd-4019-dbf7-714b66ea4c3e"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "scoring = ['precision', 'recall', 'f1']\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# Store results\n",
        "results = []\n",
        "model_results = []\n",
        "Test_results = []\n",
        "for name,model in models:\n",
        "\n",
        "  model_pipeline = Pipeline(steps=[('Preprocessing', preprocessing),('Model', model)])#\n",
        "\n",
        "  scores  = cross_validate(model_pipeline, x_train, y_train, cv= cv, scoring= scoring, return_train_score= True, n_jobs= -1,error_score='raise')\n",
        "  print(f\"Model: {name}\")\n",
        " # Take the mean for each score\n",
        "  for metric in scoring:\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "\n",
        "  print(pd.DataFrame(model_results))\n",
        "  model_results=[]\n",
        "  print(\"***********************************************************************\")\n",
        "     # Fit on full training data\n",
        "\n",
        "  model_pipeline.fit(x_train, y_train)\n",
        "  y_pred = model_pipeline.predict(x_test)\n",
        "  report = classification_report(y_test, y_pred, output_dict=True)\n",
        "  test_report_df = pd.DataFrame(report).transpose()\n",
        "  print(test_report_df)\n",
        "  print(\"***********************************************************************\")\n",
        "results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "g47O9fTqFNQQ",
        "outputId": "694ced6c-4973-4cf6-b1b2-4e072e4d3c3f"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(\n",
        "    results_df,\n",
        "    x='Model',\n",
        "    y='Score',\n",
        "    color='Set',\n",
        "    facet_col='Metric',\n",
        "    barmode='group',\n",
        "    title='Model Comparison (Train vs Test Performance)',\n",
        "    text='Score'\n",
        ")\n",
        "\n",
        "# Improve visuals\n",
        "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
        "fig.update_layout(\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    title_x=0.5,\n",
        "    title_font_size=22,\n",
        "    legend_title_text='Dataset'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y87UOl2s9kCR"
      },
      "source": [
        "## SMOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IISUN6Ty9kCR"
      },
      "outputs": [],
      "source": [
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "models = [\n",
        "    ('Logistic Regression', LogisticRegression(random_state= 42, n_jobs= -1)),\n",
        "   # ('KNN', KNeighborsClassifier(n_jobs= -1)),\n",
        "    ('Gaussian NB', GaussianNB()),\n",
        "    ('Decision Tree', DecisionTreeClassifier(random_state= 42)),\n",
        "    ('Random Forest', RandomForestClassifier(random_state= 42, n_jobs= -1)),\n",
        "    ('XGBoost', XGBClassifier(random_state=42,n_jobs=-1)),\n",
        "   ('CatBoost', CatBoostClassifier(allow_writing_files=False, random_state=42,thread_count=-1)),# order must match class indices (0 = No, 1 = Yes)  ,thread_count =use all available CPU cores\n",
        "   ('LightGBM', LGBMClassifier(random_state=42, n_jobs=-1))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLRyAoXC9kCR",
        "outputId": "9411fdcd-d12a-48bb-aee3-6560382a13b5"
      },
      "outputs": [],
      "source": [
        "scoring = ['precision', 'recall', 'f1']\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# Store results\n",
        "results = []\n",
        "for name,model in models:\n",
        "  model_pipeline = ImbPipeline(steps=[('Preprocessing', preprocessing), ('SMOTE', smote),('Model', model)])#\n",
        "\n",
        "  scores  = cross_validate(model_pipeline, x_train, y_train, cv= cv, scoring= scoring, return_train_score= True, n_jobs= -1,error_score='raise')\n",
        "  print(f\"Model: {name}\")\n",
        "\n",
        "  for metric in scoring:\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "  print(pd.DataFrame(model_results))\n",
        "  model_results=[]\n",
        "  print(\"***********************************************************************\")\n",
        "     # Fit on full training data\n",
        "\n",
        "  model_pipeline.fit(x_train, y_train)\n",
        "  y_pred = model_pipeline.predict(x_test)\n",
        "  report = classification_report(y_test, y_pred, output_dict=True)\n",
        "  test_report_df = pd.DataFrame(report).transpose()\n",
        "  print(test_report_df)\n",
        "  print(\"***********************************************************************\")\n",
        "results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Ky4tEQ0T9kCR",
        "outputId": "8f846d08-85c0-4426-dfaa-4c7e6f0f86f5"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(\n",
        "    results_df,\n",
        "    x='Model',\n",
        "    y='Score',\n",
        "    color='Set',\n",
        "    facet_col='Metric',\n",
        "    barmode='group',\n",
        "    title='Model Comparison (Train vs Test Performance)',\n",
        "    text='Score'\n",
        ")\n",
        "\n",
        "# Improve visuals\n",
        "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
        "fig.update_layout(\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    title_x=0.5,\n",
        "    title_font_size=22,\n",
        "    legend_title_text='Dataset'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAaHbDJlcPge"
      },
      "source": [
        "## Hyper Parametr Randomized search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeZCygwDlUUp"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    ('Logistic Regression',\n",
        "    LogisticRegression(class_weight=\"balanced\",random_state= 42, n_jobs= -1),\n",
        "    {\"Model__C\":[0.01, 0.1, 1, 10, 100],\"Model__penalty\":['l1', 'l2']}),\n",
        "\n",
        "    #('Decision Tree',\n",
        "     # DecisionTreeClassifier(class_weight=\"balanced\",random_state= 42),\n",
        "      #{\"Model__max_depth\": [3, 5, 7, 9,21,None]}),\n",
        "\n",
        "    ('Random Forest',\n",
        "      RandomForestClassifier(class_weight=\"balanced\",random_state= 42, n_jobs= -1),\n",
        "      {\"Model__n_estimators\": [2,3,5,10,50,100, 300, 500],\"Model__max_depth\": [2,5, 10, 15,21 ]}\n",
        "    ),\n",
        "\n",
        "     ('XGBoost',\n",
        "     XGBClassifier(scale_pos_weight=XGBoost_scale_pos_weight,random_state=42, n_jobs=-1),\n",
        "     { \"Model__n_estimators\": [2,3,5,10,50,100,500],\"Model__max_depth\": [3, 5, 10, 15,21],\"Model__reg_lambda\":[1,2,5,0.1,0.2,0.5]}\n",
        "     ),\n",
        "     #reg_alpha → L1,\"Model__reg_alpha\":[0.1,0.2,0.5,2,3]\n",
        "     #reg_lambda → L2\n",
        "\n",
        "    #('CatBoost',\n",
        "     #CatBoostClassifier(allow_writing_files=False,class_weights=[w0, w1],random_state=42, thread_count=-1),\n",
        "     #{\"Model__depth\": [4, 6, 8, 10,15,21]}),# order must match class indices w0,w1 (0 = No, 1 = Yes)  ,thread_count =use all available CPU cores\n",
        "\n",
        "    ('LightGBM',\n",
        "    LGBMClassifier(class_weight='balanced',random_state=42, n_jobs=-1),\n",
        "    {\"Model__n_estimators\": [2,3,5,10,50,100,200, 400, 600]})\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNnt7LTOccTy",
        "outputId": "bed056d5-cdb1-4532-d01e-2129d7aa6c29"
      },
      "outputs": [],
      "source": [
        "scoring = ['precision', 'recall', 'f1']\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# Store results\n",
        "results = []\n",
        "for name,model,HyperParameters in models:\n",
        "  model_pipeline = ImbPipeline(steps=[('Preprocessing', preprocessing),('Model', model)])#\n",
        "\n",
        "\n",
        "  search = RandomizedSearchCV(\n",
        "        estimator=model_pipeline,\n",
        "        param_distributions=HyperParameters,\n",
        "        n_iter=5,\n",
        "        scoring=\"recall\",\n",
        "        cv=cv,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "  search.fit(x_train, y_train)\n",
        "\n",
        "  print(f\"Model: {name}\")\n",
        "\n",
        "  best_model = search.best_estimator_\n",
        "  print(f\"Best Parameters: {search.best_params_}\")\n",
        "\n",
        "  scores  = cross_validate(best_model, x_train, y_train, cv= cv, scoring= scoring, return_train_score= True, n_jobs= -1,error_score='raise')\n",
        "  # Take the mean for each score\n",
        "  for metric in scoring:\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "  print(pd.DataFrame(model_results))\n",
        "  model_results=[]\n",
        "  print(\"***********************************************************************\")\n",
        "     # Fit on full training data\n",
        "\n",
        "  best_model.fit(x_train, y_train)\n",
        "  y_pred = best_model.predict(x_test)\n",
        "  report = classification_report(y_test, y_pred, output_dict=True)\n",
        "  test_report_df = pd.DataFrame(report).transpose()\n",
        "  print(test_report_df)\n",
        "  print(\"***********************************************************************\")\n",
        "results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "74VZiXYmviRd",
        "outputId": "e1386188-744e-48de-f8a5-5e5107589351"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(\n",
        "    results_df,\n",
        "    x='Model',\n",
        "    y='Score',\n",
        "    color='Set',\n",
        "    facet_col='Metric',\n",
        "    barmode='group',\n",
        "    title='Model Comparison (Train vs Test Performance)',\n",
        "    text='Score'\n",
        ")\n",
        "\n",
        "# Improve visuals\n",
        "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
        "fig.update_layout(\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    title_x=0.5,\n",
        "    title_font_size=22,\n",
        "    legend_title_text='Dataset'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxXBeHql9kCT"
      },
      "source": [
        "## Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHdaCuuo9kCT"
      },
      "source": [
        "### VarianceThreshold\n",
        "VarianceThreshold removes features that have little or no variability across samples.\n",
        "If a feature is almost always the same (e.g., 99% of values = 1), it adds no predictive power — so we drop it.\n",
        "This step is unsupervised (does not use y) and helps reduce noise and dataset dimensionality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS-Hhnoh9kCT"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# threshold=0 means remove features with same value in all rows\n",
        "# threshold=0.01 removes those with <1% variance\n",
        "feature_selector = VarianceThreshold(threshold=0)\n",
        "models = [\n",
        "    ('Logistic Regression', LogisticRegression(class_weight=\"balanced\",random_state= 42, n_jobs= -1)),\n",
        "   # ('KNN', KNeighborsClassifier(n_jobs= -1)),\n",
        "    ('Gaussian NB', GaussianNB()),\n",
        "    ('Decision Tree', DecisionTreeClassifier(class_weight=\"balanced\",random_state= 42)),\n",
        "    ('Random Forest', RandomForestClassifier(class_weight=\"balanced\",random_state= 42, n_jobs= -1)),\n",
        "    ('XGBoost', XGBClassifier(scale_pos_weight=XGBoost_scale_pos_weight,random_state=42,n_jobs=-1)),\n",
        "   ('CatBoost', CatBoostClassifier(allow_writing_files=False,class_weights=[w0, w1], random_state=42,thread_count=-1)),# order must match class indices (0 = No, 1 = Yes)  ,thread_count =use all available CPU cores\n",
        "   ('LightGBM', LGBMClassifier(class_weight='balanced',random_state=42, n_jobs=-1))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZlgwyBm9kCT",
        "outputId": "76e3acf8-2e00-4429-905b-c1ac8606ce47"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "scoring = ['precision', 'recall', 'f1']\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# Store results\n",
        "results = []\n",
        "model_results = []\n",
        "Test_results = []\n",
        "for name,model in models:\n",
        "\n",
        "  model_pipeline = Pipeline(steps=[('Preprocessing', preprocessing),('variance_filter', feature_selector),('Model', model)])#\n",
        "\n",
        "  scores  = cross_validate(model_pipeline, x_train, y_train, cv= cv, scoring= scoring, return_train_score= True, n_jobs= -1,error_score='raise')\n",
        "  print(f\"Model: {name}\")\n",
        " # Take the mean for each score\n",
        "  for metric in scoring:\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "\n",
        "  print(pd.DataFrame(model_results))\n",
        "  model_results=[]\n",
        "  print(\"***********************************************************************\")\n",
        "     # Fit on full training data\n",
        "\n",
        "  model_pipeline.fit(x_train, y_train)\n",
        "  y_pred = model_pipeline.predict(x_test)\n",
        "  report = classification_report(y_test, y_pred, output_dict=True)\n",
        "  test_report_df = pd.DataFrame(report).transpose()\n",
        "  print(test_report_df)\n",
        "  print(\"***********************************************************************\")\n",
        "results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "bCiamBwq9kCU",
        "outputId": "bb8c830a-987f-45a3-c4d7-bbcc1495db5b"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(\n",
        "    results_df,\n",
        "    x='Model',\n",
        "    y='Score',\n",
        "    color='Set',\n",
        "    facet_col='Metric',\n",
        "    barmode='group',\n",
        "    title='Model Comparison (Train vs Test Performance)',\n",
        "    text='Score'\n",
        ")\n",
        "\n",
        "# Improve visuals\n",
        "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
        "fig.update_layout(\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    title_x=0.5,\n",
        "    title_font_size=22,\n",
        "    legend_title_text='Dataset'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUlxqbuS9kCU"
      },
      "source": [
        "### KBSelect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMqOkdj99kCU"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest,mutual_info_classif\n",
        "\n",
        "\n",
        "models = [\n",
        "    ('Logistic Regression', LogisticRegression(class_weight=\"balanced\",random_state= 42, n_jobs= -1)),\n",
        "   # ('KNN', KNeighborsClassifier(n_jobs= -1)),\n",
        "    #('Gaussian NB', GaussianNB()),\n",
        "    #('Decision Tree', DecisionTreeClassifier(class_weight=\"balanced\",random_state= 42)),\n",
        "    #('Random Forest', RandomForestClassifier(class_weight=\"balanced\",random_state= 42, n_jobs= -1)),\n",
        "    #('XGBoost', XGBClassifier(scale_pos_weight=XGBoost_scale_pos_weight,random_state=42,n_jobs=-1)),\n",
        "    #('CatBoost', CatBoostClassifier(allow_writing_files=False,class_weights=[w0, w1], random_state=42,thread_count=-1)),# order must match class indices (0 = No, 1 = Yes)  ,thread_count =use all available CPU cores\n",
        "    ('LightGBM', LGBMClassifier(class_weight='balanced',random_state=42, n_jobs=-1))\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77D7TvV69kCU",
        "outputId": "fe7bcfc4-d911-4d26-c386-7a120d901e7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "scoring = ['precision', 'recall', 'f1']\n",
        "HyperParameters = {'kbest__k': [10, 20, 30]}\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# Store results\n",
        "results = []\n",
        "model_results = []\n",
        "Test_results = []\n",
        "for name,model in models:\n",
        "\n",
        "  model_pipeline = Pipeline(steps=[('Preprocessing', preprocessing),('kbest', SelectKBest(score_func=mutual_info_classif)),('Model', model)])#\n",
        "\n",
        "  search = RandomizedSearchCV(\n",
        "        estimator=model_pipeline,\n",
        "        param_distributions=HyperParameters,\n",
        "        n_iter=5,\n",
        "        scoring=\"recall\",\n",
        "        cv=cv,\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "  search.fit(x_train, y_train)\n",
        "\n",
        "  print(f\"Model: {name}\")\n",
        "\n",
        "  best_model = search.best_estimator_\n",
        "  print(f\"Best Parameters: {search.best_params_}\")\n",
        "\n",
        "  scores  = cross_validate(best_model, x_train, y_train, cv= cv, scoring= scoring, return_train_score= True, n_jobs= -1,error_score='raise')\n",
        "  # Take the mean for each score\n",
        "  for metric in scoring:\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "\n",
        "  print(pd.DataFrame(model_results))\n",
        "  model_results=[]\n",
        "  print(\"***********************************************************************\")\n",
        "     # Fit on full training data\n",
        "\n",
        "  best_model.fit(x_train, y_train)\n",
        "  y_pred = best_model.predict(x_test)\n",
        "  report = classification_report(y_test, y_pred, output_dict=True)\n",
        "  test_report_df = pd.DataFrame(report).transpose()\n",
        "  print(test_report_df)\n",
        "  print(\"***********************************************************************\")\n",
        "results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "5F8ZyJTV9kCU",
        "outputId": "dbe5c572-60c6-4e8a-8a11-8c192eb1ff86"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(\n",
        "    results_df,\n",
        "    x='Model',\n",
        "    y='Score',\n",
        "    color='Set',\n",
        "    facet_col='Metric',\n",
        "    barmode='group',\n",
        "    title='Model Comparison (Train vs Test Performance)',\n",
        "    text='Score'\n",
        ")\n",
        "\n",
        "# Improve visuals\n",
        "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
        "fig.update_layout(\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    title_x=0.5,\n",
        "    title_font_size=22,\n",
        "    legend_title_text='Dataset'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKjrm06zhvuJ"
      },
      "source": [
        "### Embedded methods\n",
        "- SelectFromModel\n",
        "- parameters:\n",
        "- threshold='mean' → keep features with importance > average\n",
        "- threshold='median' → keep half of the features\n",
        "- threshold=0.02 → keep all features with importance > 0.02\n",
        "- max_features=10 → keep only top 10 features (ignores threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCfpwW7GiBv3"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "models = [\n",
        "    ('Logistic Regression', LogisticRegression(class_weight=\"balanced\",random_state= 42, n_jobs= -1)),\n",
        "\n",
        "    ('Decision Tree', DecisionTreeClassifier(class_weight=\"balanced\",random_state= 42)),\n",
        "    ('Random Forest', RandomForestClassifier(class_weight=\"balanced\",random_state= 42, n_jobs= -1)),\n",
        "    ('XGBoost', XGBClassifier(scale_pos_weight=XGBoost_scale_pos_weight,random_state=42,n_jobs=-1)),\n",
        "    ('CatBoost', CatBoostClassifier(allow_writing_files=False,class_weights=[w0, w1], random_state=42,thread_count=-1)),# order must match class indices (0 = No, 1 = Yes)  ,thread_count =use all available CPU cores\n",
        "    ('LightGBM', LGBMClassifier(class_weight='balanced',random_state=42, n_jobs=-1))\n",
        "]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC7j1oDNJG3u",
        "outputId": "4e0ee2a0-a839-4780-c918-80905543f7fc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "scoring = ['precision', 'recall', 'f1']\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "# Store results\n",
        "results = []\n",
        "model_results = []\n",
        "Test_results = []\n",
        "for name,model in models:\n",
        "\n",
        "  model_pipeline = Pipeline(steps=[('Preprocessing', preprocessing),(\"FeatureSelector\",SelectFromModel(model, max_features=20)),('Model', model)])#\n",
        "\n",
        "  scores  = cross_validate(model_pipeline, x_train, y_train, cv= cv, scoring= scoring, return_train_score= True, n_jobs= -1,error_score='raise')\n",
        "  print(f\"Model: {name}\")\n",
        " # Take the mean for each score\n",
        "  for metric in scoring:\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Train',\n",
        "            'Score': scores[f'train_{metric}'].mean()\n",
        "        })\n",
        "        model_results.append({\n",
        "            'Model': name,\n",
        "            'Metric': metric,\n",
        "            'Set': 'Validation',\n",
        "            'Score': scores[f'test_{metric}'].mean()\n",
        "        })\n",
        "\n",
        "  print(pd.DataFrame(model_results))\n",
        "  model_results=[]\n",
        "  print(\"***********************************************************************\")\n",
        "     # Fit on full training data\n",
        "\n",
        "  model_pipeline.fit(x_train, y_train)\n",
        "  y_pred = model_pipeline.predict(x_test)\n",
        "  report = classification_report(y_test, y_pred, output_dict=True)\n",
        "  test_report_df = pd.DataFrame(report).transpose()\n",
        "  print(test_report_df)\n",
        "  print(\"***********************************************************************\")\n",
        "results_df = pd.DataFrame(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "3rT3XwNiJQBo",
        "outputId": "f9f0b576-3579-4c58-f272-ce5ac8383996"
      },
      "outputs": [],
      "source": [
        "fig = px.bar(\n",
        "    results_df,\n",
        "    x='Model',\n",
        "    y='Score',\n",
        "    color='Set',\n",
        "    facet_col='Metric',\n",
        "    barmode='group',\n",
        "    title='Model Comparison (Train vs Test Performance)',\n",
        "    text='Score'\n",
        ")\n",
        "\n",
        "# Improve visuals\n",
        "fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')\n",
        "fig.update_layout(\n",
        "    yaxis=dict(range=[0, 1]),\n",
        "    title_x=0.5,\n",
        "    title_font_size=22,\n",
        "    legend_title_text='Dataset'\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YZcIwQUwwdX"
      },
      "source": [
        "# Best Model\n",
        "Light GPM\n",
        "- validation Recall 0.78\n",
        "- test Recall 0.81017\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTq3XKdOyMoh",
        "outputId": "7de125c1-a0c1-4b9d-95a2-4cb9f5e86f92"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "\n",
        "    ('LightGBM', LGBMClassifier(class_weight='balanced',random_state=42, n_jobs=-1))\n",
        "]\n",
        "name, model = models[0]\n",
        "model_pipeline = Pipeline(steps=[('Preprocessing', preprocessing),('Model', model)])#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_pipeline.fit(x_train, y_train)\n",
        "y_pred = model_pipeline.predict(x_test)\n",
        "report = classification_report(y_test, y_pred, output_dict=True)\n",
        "test_report_df = pd.DataFrame(report).transpose()\n",
        "print(test_report_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu-Y72Ux6PUt",
        "outputId": "d6b211e4-7851-4c78-d412-38e7e0e1b87e"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(model_pipeline, \"LightGPM.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVeoBMUB8Xyc"
      },
      "source": [
        "# Streamlet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VviTi2QM8pZb",
        "outputId": "6d0af495-bab4-41a1-d679-dd8bc7243948"
      },
      "outputs": [],
      "source": [
        "#!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuTMBBh68XP-"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrVroEOyGT7T",
        "outputId": "e175fb42-7f93-49e3-b8af-115eb688667f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting HeartAttack_Streamlet.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile HeartAttack_Streamlet.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from imblearn.pipeline import  Pipeline\n",
        "from sklearn.impute import  SimpleImputer, KNNImputer\n",
        "from sklearn.preprocessing import  RobustScaler, OneHotEncoder, OrdinalEncoder\n",
        "from category_encoders import  BinaryEncoder\n",
        "from imblearn.over_sampling import  SMOTE\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "st.set_page_config(layout= 'wide', page_title= 'Heart Attack Prediction Project')\n",
        "html_title = \"<h1 style=color:white;text-align:center;> Heart Attack Prediction Project </h1>\"\n",
        "st.markdown(html_title, unsafe_allow_html=True)\n",
        "\n",
        "df = pd.read_csv('HeartAttack_cleaned_df.csv')\n",
        "df.dropna(inplace=True)\n",
        "st.dataframe(df)\n",
        "\n",
        "Sex = st.sidebar.radio('Sex', df.Sex.unique())\n",
        "PhysicalHealthDays= st.sidebar.slider('Physical Health Days', int(df.PhysicalHealthDays.min()), int(df.PhysicalHealthDays.max()), int(df.PhysicalHealthDays.mean()))\n",
        "MentalHealthDays= st.sidebar.slider('Mental Health Days', int(df.MentalHealthDays.min()), int(df.MentalHealthDays.max()), int(df.MentalHealthDays.mean()))\n",
        "SleepHours= st.sidebar.slider('Sleep Hours', float(df.SleepHours.min()), float(df.SleepHours.max()), float(df.SleepHours.mean()))\n",
        "HeightInMeters= st.sidebar.slider('Height In Meters', float(df.HeightInMeters.min()), float(df.HeightInMeters.max()), float(df.HeightInMeters.mean()))\n",
        "BMI= st.sidebar.slider('BMI', float(df.BMI.min()), float(df.BMI.max()), float(df.BMI.mean()))\n",
        "GeneralHealth = st.sidebar.selectbox('PLease provid General Health ', df.GeneralHealth.unique())\n",
        "LastCheckupTime = st.sidebar.selectbox('When was your last checkup?', df.LastCheckupTime.unique())\n",
        "PhysicalActivities = st.sidebar.radio('Do you do physical activities?', df.PhysicalActivities.unique())\n",
        "RemovedTeeth= st.sidebar.selectbox('Removed Teeth',df.RemovedTeeth.unique())\n",
        "HadAngina= st.sidebar.radio('Had Angina',df.HadAngina.unique())\n",
        "HadStroke= st.sidebar.radio('Had Stroke',df.HadStroke.unique())\n",
        "HadCOPD= st.sidebar.radio('Had COPD',df.HadCOPD.unique())\n",
        "HadDepressiveDisorder= st.sidebar.radio('Had Depressive Disorder',df.HadDepressiveDisorder.unique())\n",
        "HadKidneyDisease= st.sidebar.radio('Had Kidney Disease',df.HadKidneyDisease.unique())\n",
        "HadArthritis= st.sidebar.radio('Had Arthritis',df.HadArthritis.unique())\n",
        "HadDiabetes= st.sidebar.selectbox('Had Diabetes',df.HadDiabetes.unique())\n",
        "DeafOrHardOfHearing= st.sidebar.radio('Deaf Or Hard Of Hearing',df.DeafOrHardOfHearing.unique())\n",
        "BlindOrVisionDifficulty= st.sidebar.radio('Blind Or Vision Difficulty',df.BlindOrVisionDifficulty.unique())\n",
        "DifficultyConcentrating= st.sidebar.radio('Difficulty Concentrating',df.DifficultyConcentrating.unique())\n",
        "DifficultyWalking= st.sidebar.radio('Difficulty Walking',df.DifficultyWalking.unique())\n",
        "DifficultyDressingBathing= st.sidebar.radio('Difficulty Dressing Bathing',df.DifficultyDressingBathing.unique())\n",
        "DifficultyErrands= st.sidebar.radio('Difficulty Errands',df.DifficultyErrands.unique())\n",
        "SmokerStatus= st.sidebar.selectbox('Smoker Status',df.SmokerStatus.unique())\n",
        "ECigaretteUsage= st.sidebar.selectbox('E-Cigarette Usage',df.ECigaretteUsage.unique())\n",
        "ChestScan= st.sidebar.radio('Chest Scan',df.ChestScan.unique())\n",
        "AgeCategory= st.sidebar.selectbox('Age Category',df.AgeCategory.unique())\n",
        "AlcoholDrinkers= st.sidebar.radio('Alcohol Drinkers',df.AlcoholDrinkers.unique())\n",
        "HIVTesting= st.sidebar.radio('HIV Testing',df.HIVTesting.unique())\n",
        "FluVaxLast12= st.sidebar.radio('Flu Vax Last 12 Months',df.FluVaxLast12.unique())\n",
        "PneumoVaxEver= st.sidebar.radio('Pneumo Vax Ever',df.PneumoVaxEver.unique())\n",
        "TetanusLast10Tdap= st.sidebar.selectbox('Tetanus Last 10 Tdap',df.TetanusLast10Tdap.unique())\n",
        "HighRiskLastYear= st.sidebar.radio('High Risk Last Year',df.HighRiskLastYear.unique())\n",
        "CovidPos= st.sidebar.selectbox('Covid Positive',df.CovidPos.unique())\n",
        "\n",
        "# Import Model\n",
        "Model = joblib.load('LightGPM.pkl')\n",
        "\n",
        "input_cols = df.columns.drop('HadHeartAttack')\n",
        "input_data = pd.DataFrame(columns=input_cols,data= [ [Sex,GeneralHealth,PhysicalHealthDays,MentalHealthDays,LastCheckupTime\n",
        ",PhysicalActivities,SleepHours,RemovedTeeth,HadAngina,HadStroke,HadCOPD,HadDepressiveDisorder,HadKidneyDisease,HadArthritis\n",
        ",HadDiabetes,DeafOrHardOfHearing,BlindOrVisionDifficulty,DifficultyConcentrating,DifficultyWalking,DifficultyDressingBathing\n",
        ",DifficultyErrands,SmokerStatus,ECigaretteUsage,ChestScan,AgeCategory,HeightInMeters,BMI,AlcoholDrinkers\n",
        ",HIVTesting,FluVaxLast12,PneumoVaxEver,TetanusLast10Tdap,HighRiskLastYear,CovidPos] ])\n",
        "\n",
        "if st.button('Predict'):\n",
        "\n",
        "    result = Model.predict(input_data)[0]\n",
        "\n",
        "    if result == 0:\n",
        "        st.write('Heart Attack : NO')\n",
        "\n",
        "    else:\n",
        "        st.write('Heart Attack : YES')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNwpONVmGrOG",
        "outputId": "857d5b09-5080-4363-b614-0ad480dcb4c7"
      },
      "outputs": [],
      "source": [
        "! streamlit run HeartAttack_Streamlet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install pipreqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Not scanning for jupyter notebooks.\n",
            "WARNING: Import named \"category_encoders\" not found locally. Trying to resolve it at the PyPI server.\n",
            "WARNING: Import named \"category_encoders\" was resolved to \"category-encoders:2.8.1\" package (https://pypi.org/project/category-encoders/).\n",
            "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
            "WARNING: Import named \"pandas\" not found locally. Trying to resolve it at the PyPI server.\n",
            "WARNING: Import named \"pandas\" was resolved to \"pandas:2.3.3\" package (https://pypi.org/project/pandas/).\n",
            "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
            "WARNING: Import named \"scikit_learn\" not found locally. Trying to resolve it at the PyPI server.\n",
            "WARNING: Import named \"scikit_learn\" was resolved to \"scikit-learn:1.7.2\" package (https://pypi.org/project/scikit-learn/).\n",
            "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
            "INFO: Successfully saved requirements file in .\\requirements.txt\n"
          ]
        }
      ],
      "source": [
        "import pipreqs\n",
        "\n",
        "! pipreqs ."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qmKqi0vsWFAx",
        "0wi54e9ufEAq",
        "j6YKyGl7mh35",
        "e6pQ69_Tc4fh",
        "fU8e_Re25TLt"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
